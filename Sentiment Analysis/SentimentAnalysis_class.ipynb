{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class to predict sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file to be used in the class must have the following format:\n",
    "\n",
    "![info_csv](foto_info_csv.PNG)\n",
    "\n",
    "- Be a .csv file\n",
    "- a single column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras_preprocessing.text import tokenizer_from_json\n",
    "import json\n",
    "import re\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "class model_sentiment_test():\n",
    "    \"\"\"Class that allows automated predictions\n",
    "         in the text.\n",
    "       \n",
    "         args:\n",
    "         ----------\n",
    "         file_text (str): .csv text file\n",
    "        \n",
    "         \"\"\"\n",
    "    def __init__(self, file_text:str):\n",
    "        self.file_text = file_text\n",
    "        self.predictions = None        #model predictions\n",
    "        self.df = None                 #raw data frame\n",
    "        self.df_clean = None           #processed data frame\n",
    "        self.df_result = None          #dataframe with predictions\n",
    "        \n",
    "        if \".csv\" in file_text:\n",
    "            self.__read_pandas()\n",
    "        else:\n",
    "            print(\"The file does not have a .csv extension\")\n",
    "        \n",
    "    def __read_pandas(self):\n",
    "        \"\"\"Load the data into a dataframe\"\"\"     \n",
    "        self.df = pd.read_csv(self.file_text).iloc[:,0]\n",
    "    \n",
    "    @staticmethod\n",
    "    def __remove_emojis(data):\n",
    "        \"\"\"Remove emojis from messages\"\"\"\n",
    "        \n",
    "        emoj = re.compile(\"[\"\n",
    "            u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "            u\"\\U0001F300-\\U0001F5FF\"  # symbols and pictograms\n",
    "            u\"\\U0001F680-\\U0001F6FF\"  # transport and map symbols\n",
    "            u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "            u\"\\U00002500-\\U00002BEF\"  # chinese symbols\n",
    "                      \"]+\", re.UNICODE)\n",
    "        return re.sub(emoj, '', data)\n",
    "    \n",
    "    @staticmethod\n",
    "    def __tokenizar_stopwords(text, *stop_words):\n",
    "        \"\"\"Remove stopwords\"\"\"\n",
    "        output = [word for word in text.split() if word not in stop_words]        \n",
    "        return ' '.join(output)\n",
    "    \n",
    "    def __treatment(self):\n",
    "        \"\"\"text treatment\"\"\"\n",
    "        df = self.df.copy()\n",
    "        \n",
    "        #Remove accents\n",
    "        a,b = 'áéíóúüÁÉÍÓÚÜ','aeiouuAEIOUU'\n",
    "        trans = str.maketrans(a,b)\n",
    "        df = df.str.translate(trans)\n",
    "        print(\"Processing ... Step [1/13]\", end = \"\\r\")\n",
    "        \n",
    "        #Remove line breaks and tabs\n",
    "        df = df.str.replace(\"[\\n,\\t]\", ' ', regex=True)\n",
    "        print(\"Processing ... Step [2/13]\", end = \"\\r\")\n",
    "        \n",
    "        #Remove tags, links and numbers\n",
    "        df = df.str.replace(\"(@[A-Za-z0-9\\_\\-\\.]+)|(\\w+:\\/\\/\\S+)|(\\d+[\\w+\\-\\/]*)\", \"\", regex=True) \n",
    "        print(\"Processing ... Step [3/13]\", end = \"\\r\")\n",
    "        \n",
    "        #Remove special characters\n",
    "        df = df.str.replace(\"[#,&,$,!,',),(,-,*,;,:,|,\\\",.,?,¿,¡]\",'',regex=True)\n",
    "        print(\"Processing ... Paso [4/13]\", end = \"\\r\")\n",
    "        \n",
    "        #Remove emoji\n",
    "        df = df.apply(self.__remove_emojis)\n",
    "        print(\"Processing ... Paso [5/13]\", end = \"\\r\")\n",
    "        \n",
    "        #Remove spaces at the beginning and end\n",
    "        df = df.str.strip()\n",
    "        print(\"Processing ... Paso [6/13]\", end = \"\\r\")\n",
    "        \n",
    "        #Transform to lowercase\n",
    "        df = df.str.lower()\n",
    "        print(\"Processing ... Paso [7/13]\", end = \"\\r\")\n",
    "        \n",
    "        #Remove duplicates where both attributes are the same\n",
    "        df = df[~df.duplicated()]\n",
    "        print(\"Processing ... Paso [8/13]\", end = \"\\r\")\n",
    "        \n",
    "        #Remove stopwords\n",
    "        with open(\"stopwords.pickle\", \"rb\") as f:\n",
    "            stop_words = pickle.load(f)\n",
    "        df = df.apply(self.__tokenizar_stopwords, args=stop_words)\n",
    "        print(\"Processing ... Paso [9/13]\", end = \"\\r\")\n",
    "        \n",
    "        #Remove empty cells\n",
    "        df.replace('', np.nan, inplace=True)\n",
    "        df.dropna(inplace=True)\n",
    "        print(\"Processing ... Paso [10/13]\", end = \"\\r\")\n",
    "        \n",
    "        self.df_clean = df.copy()\n",
    "        \n",
    "    def evaluation(self):\n",
    "        \"\"\"Predict the sentiment from the text\"\"\"\n",
    "        self.__treatment()\n",
    "        \n",
    "        X = self.df_clean.values\n",
    "        \n",
    "        #Change text according to the sequence of values of the dictionary\n",
    "        with open('tokenizer.json') as f:\n",
    "            data = json.load(f)\n",
    "            tokenizer = tokenizer_from_json(data)\n",
    "        X = tokenizer.texts_to_sequences(X)\n",
    "        print(\"Processing ... Paso [11/13]\", end = \"\\r\")\n",
    "        \n",
    "        #Set sequence input length\n",
    "        X = pad_sequences(X, 40)\n",
    "        print(\"Processing ... Paso [12/13]\", end = \"\\r\")\n",
    "        \n",
    "        #Change input form\n",
    "        X_ = X.reshape(X.shape[0],X.shape[1],1)\n",
    "        print(\"Processing ... Paso [13/13]\", end = \"\\r\")\n",
    "        \n",
    "        #Model loaded\n",
    "        model = keras.models.load_model('best_model.hdf5')\n",
    "        print(\"Predicting ... ... ... ... ...\", end = \"\\r\")\n",
    "        \n",
    "        #Calculation of predictions\n",
    "        predictions = model.predict(X_).reshape(1,-1)[0]\n",
    "        self.predictions = [0 if x < 0.5 else 1 for x in predictions]\n",
    "        \n",
    "        self.df_result = self.df.iloc[self.df_clean.index].to_frame()\n",
    "        self.df_result['sentimiento_real_pred'] = self.predictions\n",
    "        print(\"Ended process ... ... ... ...\", end = \"\\r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model instance and data load\n",
    "sentiment = model_sentiment_test('data_without_target.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ended process ... ... ... ....\r"
     ]
    }
   ],
   "source": [
    "# Data processing and prediction\n",
    "sentiment.evaluation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentimiento_real_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@Vladi_VillegasP @YouTube @laidygomezf  una co...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@Vladialacarta @laidygomezf  yo estoy Orgullos...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#SoyComunicadorClap \\n#Táchira: \\n\"Hasta el ir...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@VTVcanal8 La \"Reina del Tachira\" Protectora y...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Un buen espaldarazo a la institucionalidad ser...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114259</th>\n",
       "      <td>También fui afectada con el ROBO que nos hizo ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114260</th>\n",
       "      <td>Estoy intentando hacer un reclamo desde el.dia...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114261</th>\n",
       "      <td>Ajá y el día de los muertos lo agarraran de pu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114262</th>\n",
       "      <td>tengo problemas con la lectura de huella deseo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114263</th>\n",
       "      <td>Jajajajajajaa claro los del banco de Venezuela...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>79139 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  \\\n",
       "0       @Vladi_VillegasP @YouTube @laidygomezf  una co...   \n",
       "1       @Vladialacarta @laidygomezf  yo estoy Orgullos...   \n",
       "2       #SoyComunicadorClap \\n#Táchira: \\n\"Hasta el ir...   \n",
       "3       @VTVcanal8 La \"Reina del Tachira\" Protectora y...   \n",
       "4       Un buen espaldarazo a la institucionalidad ser...   \n",
       "...                                                   ...   \n",
       "114259  También fui afectada con el ROBO que nos hizo ...   \n",
       "114260  Estoy intentando hacer un reclamo desde el.dia...   \n",
       "114261  Ajá y el día de los muertos lo agarraran de pu...   \n",
       "114262  tengo problemas con la lectura de huella deseo...   \n",
       "114263  Jajajajajajaa claro los del banco de Venezuela...   \n",
       "\n",
       "        sentimiento_real_pred  \n",
       "0                           0  \n",
       "1                           1  \n",
       "2                           0  \n",
       "3                           0  \n",
       "4                           0  \n",
       "...                       ...  \n",
       "114259                      1  \n",
       "114260                      1  \n",
       "114261                      1  \n",
       "114262                      1  \n",
       "114263                      1  \n",
       "\n",
       "[79139 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model output\n",
    "sentiment.df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primeras 5 predicciones [0, 1, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "preds = sentiment.predictions\n",
    "print(\"Primeras 5 predicciones {}\".format(preds[:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GeniosStudio",
   "language": "python",
   "name": "geniosstudio"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
